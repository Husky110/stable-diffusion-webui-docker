version: '3.9'
# Do not edit this file! If you want to change anything use the .env-file!

# Containers und Services
x-base_service: &base_service
  ports:
    - "${WEBUI_PORT:-7860}:7860"
  stop_signal: SIGKILL
  tty: true
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            device_ids: ['0']
            capabilities: [compute, utility]

name: webui-docker

services:
  download:
    build: ./services/download/
    profiles: ["download"]
    volumes:
      - ${VOLUMES_CHECKPOINTS}:/data/checkpoints
      - ${VOLUMES_VAE}:/data/VAE
      - ${VOLUMES_VAE_APPROX}:/data/VAE-approx
      - ${VOLUMES_GFPGAN}:/data/GFPGAN
      - ${VOLUMES_REALESRGAN}:/data/RealESRGAN
      - ${VOLUMES_CODEFORMER}:/data/Codeformer
      - ${VOLUMES_LDSR}:/data/LDSR
      - ${VOLUMES_KARLO}:/data/karlo
    user: 1000:1000
    environment:
      - INSTALL_DOWNLOAD_BASE_MODELS=${INSTALL_DOWNLOAD_BASE_MODELS}
      - INSTALL_DOWNLOAD_BASE_VAE=${INSTALL_DOWNLOAD_BASE_VAE}
      - INSTALL_DOWNLOAD_BASE_UPSCALERS=${INSTALL_DOWNLOAD_BASE_UPSCALERS}
      - INSTALL_A1111_REQUIREMENTS=${INSTALL_A1111_REQUIREMENTS}

  auto: &automatic
    <<: *base_service
    profiles: ["auto"]
    container_name: "sd-auto-gpu"
    build: ./services/AUTOMATIC1111
    image: sd-auto:67
    volumes:
      - ${A1111_OUTPUT}:/output
      - ${VOLUMES_CHECKPOINTS}:/stable-diffusion-webui/models/Stable-diffusion
      - ${VOLUMES_LORAS}:/stable-diffusion-webui/models/Lora
      - ${VOLUMES_EMBEDDINGS}:/stable-diffusion-webui/embeddings
      - ${VOLUMES_HYPERNETWORKS}:/stable-diffusion-webui/models/hypernetworks
      - ${VOLUMES_VAE}:/stable-diffusion-webui/models/VAE
      - ${VOLUMES_VAE_APPROX}:/stable-diffusion-webui/models/VAE-approx
      - ${VOLUMES_ESRGAN}:/stable-diffusion-webui/models/ESRGAN
      - Real${VOLUMES_ESRGAN}:/stable-diffusion-webui/models/RealESRGAN
      - ${VOLUMES_GFPGAN}:/stable-diffusion-webui/models/GFPGAN
      - ${VOLUMES_LDSR}:/stable-diffusion-webui/models/LSDR
      - ${VOLUMES_SWINIR}:/stable-diffusion-webui/models/SWINIR
      - ${VOLUMES_KARLO}:/stable-diffusion-webui/models/karlo
      - ${VOLUMES_CODEFORMER}:/stable-diffusion-webui/models/Codeformer
      - ${VOLUMES_A1111_CONFIGS}:/data/configs
      - ${VOLUMES_A1111_CONFIGSTATES}:/stable-diffusion-webui/config_states
      - ${VOLUMES_A1111_EXTENSIONS}:/stable-diffusion-webui/extensions
      - ${VOLUMES_A1111_CODEFOMER_WEIGHTS_FACELIB}:/stable-diffusion-webui/repositories/CodeFormer/weights/facelib
    environment:
      - CLI_ARGS=${A1111_CLI_ARGS}
      - A1111_INSTALL_RECOMMENDED_EXTENSION_REGIONALPROMPTER=${A1111_INSTALL_RECOMMENDED_EXTENSION_REGIONALPROMPTER}
      - A1111_INSTALL_RECOMMENDED_EXTENSION_CONTROLNET=${A1111_INSTALL_RECOMMENDED_EXTENSION_CONTROLNET}
      - A1111_INSTALL_RECOMMENDED_EXTENSION_TILEDVAE=${A1111_INSTALL_RECOMMENDED_EXTENSION_TILEDVAE}

  auto-cpu:
    <<: *automatic
    profiles: ["auto-cpu"]
    container_name: "sd-auto-cpu"
    deploy: {}
    environment:
      - CLI_ARGS=--no-half --precision full --allow-code --enable-insecure-extension-access --api

  invoke: &invoke
    <<: *base_service
    #TODO: VOLUMES AND SCRIPTS
    profiles: ["invoke"]
    container_name: "sd-invoke-gpu"
    build: ./services/invoke/
    image: sd-invoke:30
    volumes:
      - ./data:/data
      - ./output:/output
    environment:
      - PRELOAD=true
      - CLI_ARGS=--xformers

  # invoke-cpu:
  #   <<: *invoke
  #   profiles: ["invoke-cpu"]
  #   environment:
  #     - PRELOAD=true
  #     - CLI_ARGS=--always_use_cpu

  comfy: &comfy
    <<: *base_service
    #TODO: VOLUMES AND SCRIPTS
    profiles: ["comfy"]
    container_name: "sd-comfy-gpu"
    build: ./services/comfy/
    image: sd-comfy:5
    volumes:
      - ./data:/data
      - ./output:/output
    environment:
      - CLI_ARGS=


  comfy-cpu:
    <<: *comfy
    profiles: ["comfy-cpu"]
    container_name: "sd-comfy-gpu"
    deploy: {}
    environment:
      - CLI_ARGS=--cpu
