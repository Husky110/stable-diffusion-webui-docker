version: '3.9'
# Do not edit this file! If you want to change anything use the .env-file!
volumes:
  #General Paths
  checkpoints:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_CHECKPOINTS}
  loras:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_LORAS}
  embeddings:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_EMBEDDINGS}
  hypernetworks:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_HYPERNETWORKS}
  vae:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_VAE}
  vae_approx:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_VAE_APPROX}
  # Upscalers
  ESRGAN:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_ESRGAN}
  RealESRGAN:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_REALESRGAN}
  GFPGAN:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_GFPGAN}
  LDSR:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_LDSR}
  SWINIR:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_SWINIR}
  # Misc
  CONTROLNET:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_CONTROLNET}
  KARLO:
    driver: local-persist
    driver_opts:
      mountpoint: ${VOLUMES_KARLO}


# Containers und Services
x-base_service: &base_service
  ports:
    - "${WEBUI_PORT:-7860}:7860"
  stop_signal: SIGKILL
  tty: true
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            device_ids: ['0']
            capabilities: [compute, utility]

name: webui-docker

services:
  download:
    build: ./services/download/
    profiles: ["download"]
    volumes:
      - checkpoints:/data/checkpoints
      - vae:/data/VAE
      - vae_approx:/data/VAE-approx
      - GFPGAN:/data/GFPGAN
      - RealESRGAN:/data/RealESRGAN
      - LDSR:/data/LDSR
      - KARLO:/data/karlo
    user: 1000:1000
    environment:
      - INSTALL_DOWNLOAD_BASE_MODELS=${INSTALL_DOWNLOAD_BASE_MODELS}
      - INSTALL_DOWNLOAD_BASE_VAE=${INSTALL_DOWNLOAD_BASE_VAE}
      - INSTALL_DOWNLOAD_BASE_UPSCALERS=${INSTALL_DOWNLOAD_BASE_UPSCALERS}
      - INSTALL_A1111_REQUIREMENTS=${INSTALL_A1111_REQUIREMENTS}

  auto: &automatic
    <<: *base_service
    profiles: ["auto"]
    container_name: "sd-auto-gpu"
    build: ./services/AUTOMATIC1111
    image: sd-auto:67
    volumes:
      - ./data/models:/stable-diffusion-webui/models
      - ./data:/data
      - ./data/auto/config_states:/stable-diffusion-webui/config_states
      - ./data/auto/scripts:/stable-diffusion-webui/scripts
      - ./output:/output
      - ./caches/auto/codeformer_facelib:/codeformer_facelib
    environment:
      # Warning: XFormers improves performance, but can mess with seeds! Use with caution...
      - CLI_ARGS=--allow-code --medvram --xformers --enable-insecure-extension-access --api

  auto-cpu:
    <<: *automatic
    profiles: ["auto-cpu"]
    container_name: "sd-auto-cpu"
    deploy: {}
    environment:
      - CLI_ARGS=--no-half --precision full --allow-code --enable-insecure-extension-access --api

  invoke: &invoke
    <<: *base_service
    #TODO: VOLUMES AND SCRIPTS
    profiles: ["invoke"]
    container_name: "sd-invoke-gpu"
    build: ./services/invoke/
    image: sd-invoke:30
    volumes:
      - ./data:/data
      - ./output:/output
    environment:
      - PRELOAD=true
      - CLI_ARGS=--xformers

  # invoke-cpu:
  #   <<: *invoke
  #   profiles: ["invoke-cpu"]
  #   environment:
  #     - PRELOAD=true
  #     - CLI_ARGS=--always_use_cpu

  comfy: &comfy
    <<: *base_service
    #TODO: VOLUMES AND SCRIPTS
    profiles: ["comfy"]
    container_name: "sd-comfy-gpu"
    build: ./services/comfy/
    image: sd-comfy:5
    volumes:
      - ./data:/data
      - ./output:/output
    environment:
      - CLI_ARGS=


  comfy-cpu:
    <<: *comfy
    profiles: ["comfy-cpu"]
    container_name: "sd-comfy-gpu"
    deploy: {}
    environment:
      - CLI_ARGS=--cpu
